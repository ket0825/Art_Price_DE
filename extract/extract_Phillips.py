import requests
import json
from bs4 import BeautifulSoup
import re
import time
import random

# Phillips API ê¸°ë³¸ URL
MAKER_ID = 6740
BASE_URL = f"https://api.phillips.com/api/maker/{MAKER_ID}/lots"

# User-Agent ë¦¬ìŠ¤íŠ¸ (ëœë¤ ì„ íƒ)
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36",
    "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:94.0) Gecko/20100101 Firefox/94.0",
]

HEADERS = {
    "User-Agent": random.choice(USER_AGENTS),
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
    "Referer": "https://www.phillips.com/browse",
    "Connection": "keep-alive",
}

# ì„¸ì…˜ ìœ ì§€ (ì¿ í‚¤ í™•ë³´)
session = requests.Session()
session.headers.update(HEADERS)

# Phillips í™ˆí˜ì´ì§€ ë°©ë¬¸í•˜ì—¬ ì¿ í‚¤ ì €ì¥ (403 ë°©ì§€)
session.get("https://www.phillips.com/")
cookies = session.cookies.get_dict()  # ì¿ í‚¤ í™•ì¸

def fetch_detail_info(detail_url):
    """ìƒì„¸ í˜ì´ì§€ì—ì„œ ì¶”ê°€ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    if detail_url == "No URL":
        return {}

    # ìš”ì²­ ì „ì— ì¼ì •í•œ ë”œë ˆì´ ì¶”ê°€ (403 ë°©ì§€)
    time.sleep(random.uniform(2, 5))

    # User-Agent ë³€ê²½
    session.headers.update({"User-Agent": random.choice(USER_AGENTS)})

    # ì¿ í‚¤ í¬í•¨í•˜ì—¬ ìš”ì²­
    response = session.get(detail_url, cookies=cookies)

    if response.status_code == 403:
        print(f"âš ï¸ [403 Forbidden] Access denied to {detail_url}")
        return {}

    if response.status_code != 200:
        print(f"âš ï¸ Failed to fetch details from {detail_url}. Status: {response.status_code}")
        return {}

    soup = BeautifulSoup(response.text, "html.parser")

    detail_info = {
        "year": None,
        "artwork_type": None,
        "height_cm": None,
        "width_cm": None,
        "edition": None,
    }

    # ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
    additional_info_elem = soup.select_one(".lot-page__lot__additional-info")
    
    if additional_info_elem:
        additional_info_text = additional_info_elem.get_text(separator=" ").strip()

        # ì œì‘ ì—°ë„ ì¶”ì¶œ (4ìë¦¬ ìˆ«ì íƒìƒ‰)
        year_match = re.search(r"(\b\d{4}\b)", additional_info_text)
        if year_match:
            detail_info["year"] = int(year_match.group(1))

        # ë§¤ì²´ ì¶”ì¶œ
        material_match = re.search(r"(oil|watercolour|lithograph|screenprint|graphite|ink|acrylic|mixed media|tempera|gouache|charcoal|pastel)", additional_info_text, re.IGNORECASE)
        if material_match:
            detail_info["artwork_type"] = material_match.group(0).strip()

        # í¬ê¸° ì •ë³´ ì¶”ì¶œ (23.5 x 15.2 cm)
        size_match = re.search(r"(\d+(\.\d+)?)\s*x\s*(\d+(\.\d+)?)\s*cm", additional_info_text)
        if size_match:
            detail_info["height_cm"] = float(size_match.group(1))
            detail_info["width_cm"] = float(size_match.group(3))

        # ì—ë””ì…˜ ì •ë³´ ì¶”ì¶œ (ì˜ˆ: Edition of 100)
        edition_match = re.search(r"edition of (\d+)", additional_info_text, re.IGNORECASE)
        if edition_match:
            detail_info["edition"] = int(edition_match.group(1))
        
    return detail_info

    
def fetch_lots():
    """ê²½ë§¤ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    auction_site = "Phillips"
    # í¬ë¡¤ë§í•œ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    auction_data = []

    # í˜ì´ì§€ë„¤ì´ì…˜ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ë³€ìˆ˜
    page = 1  # ì²« í˜ì´ì§€ë¶€í„° ì‹œì‘
    total_pages = None  # ì²˜ìŒì—” ì „ì²´ í˜ì´ì§€ ìˆ˜ë¥¼ ëª¨ë¥´ë¯€ë¡œ Noneìœ¼ë¡œ ì„¤ì •

    while True:
        # API ìš”ì²­ ì‹œ í•„ìš”í•œ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°
        params = {
            "page": page,              # í˜„ì¬ í˜ì´ì§€ ë²ˆí˜¸
            "resultsperpage": 24,       # í•œ í˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜¬ ë°ì´í„° ê°œìˆ˜
            "lotStatus": "past"         # ê³¼ê±° ê²½ë§¤ ë°ì´í„° (í˜„ì¬ ì§„í–‰ ì¤‘ì€ 'upcoming'ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥)
        }

        # API ìš”ì²­ ë³´ë‚´ê¸°
        response = session.get(BASE_URL, headers=HEADERS, params=params)

        if response.status_code == 200:  
            data = response.json()  # ì‘ë‹µ ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜

            # ì „ì²´ í˜ì´ì§€ ìˆ˜ ì„¤ì • (ì²« ìš”ì²­ì—ì„œë§Œ ê°€ì ¸ì˜´), totalPagesê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 1ë¡œ ì„¤ì •
            if total_pages is None:
                total_pages = data.get("totalPages", 1)

            print(f"ğŸ“Œ Fetching page {page} of {total_pages}...")

            # ì‘ë‹µ JSONì—ì„œ 'data' í‚¤ ì•ˆì˜ ê²½ë§¤ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            for item in data.get("data", []):
                detail_url = item.get("detailLink", "No URL")

                # ë¹„ì •ìƒì  ê²½ë§¤ ì¢…ë£Œ ì‹œê°„ ì²˜ë¦¬
                auction_start = item.get("auctionStartDateTimeOffset", "0001-01-01T00:00:00")
                auction_end = item.get("auctionEndDateTimeOffset", "0001-01-01T00:00:00")
                if "0001" in auction_end:
                    if "0001" in auction_start:
                        continue  # ì‹œì‘, ì¢…ë£Œ ëª¨ë‘ 0001ë…„ì´ë©´ ë°ì´í„° ì œì™¸
                    auction_end = auction_start  # ë¹„ì •ìƒì ì¸ ì¢…ë£Œ ì‹œê°„ì„ ì‹œì‘ ì‹œê°„ìœ¼ë¡œ ëŒ€ì²´

                # ë¹„ì •ìƒì  ê²½ë§¤ê°€ê²© ì²˜ë¦¬
                price = item.get("hammerPlusBP", 0)
                if price == 0.0:
                    price = None

                # ê° í•„ë“œì—ì„œ í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ
                # transformì—ì„œ ê±°ë˜ ë‚ ì í˜•ë³€í™˜, ì˜ˆìƒ/ì‹¤ì œ ë‚™ì°°ê°€ ë‹¨ìœ„ ë³€í™˜ í•„ìš”
                lot_info = {
                    "artist": item.get("makerName", "Unknown Artist"),
                    "title": item.get("description", "No Title"),
                    "start_date": auction_start,
                    "end_date": auction_end,
                    "low_estimate": item.get("lowEstimate", 0),
                    "high_estimate": item.get("highEstimate", 0),
                    "price": price,
                    "auction_site": auction_site,
                    "year": None,
                    "artwork_type": None,
                    "edition": None,
                    "height_cm": None,
                    "width_cm": None,
                    "currency": item.get("currencySign", ""), #í™”í ë‹¨ìœ„
                }
                
                detail_data = fetch_detail_info(detail_url)
                lot_info.update(detail_data)

                auction_data.append(lot_info)

            page += 1
            if page > total_pages:
                break
        else:
            print(f"âš ï¸ Failed to fetch data on page {page}. Status code: {response.status_code}")
            break
    return auction_data

# ë°ì´í„° í¬ë¡¤ë§ ì‹¤í–‰
auction_results = fetch_lots()

# JSON íŒŒì¼ë¡œ ì €ì¥ (íŒŒì¼ëª…ì— ì‘ê°€ ID í¬í•¨)
json_filename = f"./data/phillips_auction_results_{MAKER_ID}.json"
with open(json_filename, "w", encoding="utf-8") as file:
    json.dump(auction_results, file, indent=4, ensure_ascii=False)  # JSON ì €ì¥ (ê°€ë…ì„± ìœ„í•´ indent=4)

print(f"âœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ: {json_filename}")